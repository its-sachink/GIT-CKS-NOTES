##### Lab : Security Contexts

- What is the user used to execute the sleep process within the ubuntu-sleeper pod?

    # kubectl exec ubuntu-sleeper -- whoami


- Edit the pod ubuntu-sleeper to run the sleep process with user ID 1010.

    # kubectl get pod ubuntu-sleeper -o yaml > sleeper.yaml
    # vim sleeper.yaml
    # cat sleeper.yaml | grep -i securitycontext -C 3
        spec:
        containers:
        - command:
            - sleep
            - "4800"
            image: ubuntu
            name: ubuntu-sleeper
            securityContext:
            capabilities:
                add: ["SYS_TIME"]

    # kubectl delete pod ubuntu-sleeper --force     << To delete the Pod faster.

    # kubectl apply -f sleeper.yaml 
        pod/ubuntu-sleeper created


- Now update the pod to also make use of the NET_ADMIN capability.

    # vim sleeper.yaml
        spec:
        containers:
        - command:
            - sleep
            - "4800"
            image: ubuntu
            name: ubuntu-sleeper
            securityContext:
            capabilities:
                add: ["SYS_TIME", "NET_ADMIN"]
    # kubectl delete pod ubuntu-sleeper.yaml

    # kubectl apply -f sleeper.yaml




##### Lab : Admission Controllers

- Which admission controller is enabled in this cluster which is normally disabled?.

    # cat /etc/kubernetes/manifests/kube-apiserver.yaml | grep -i enable
    - --enable-admission-plugins=NodeRestriction
    - --enable-bootstrap-token-auth=true


    # cat /etc/kubernetes/manifests/kube-apiserver.yaml | grep -i enable-admission-plugins
    - --enable-admission-plugins=NodeRestriction





-   # kubectl run nginx --image=nginx -n blue

    The previous step failed because kubernetes have NamespaceExists admission controller enabled which rejects requests to namespaces that do not exist. So, to create a namespace that does not exist automatically, we could enable the NamespaceAutoProvision admission controller
        Enable the NamespaceAutoProvision admission controller

        Note: Once you update kube-apiserver yaml file, please wait for a few minutes for the kube-apiserver to restart completely.


    # vim /etc/kubernetes/manifests/kube-apiserver.yaml

    # cat /etc/kubernetes/manifests/kube-apiserver.yaml | grep -i enable
    - --enable-admission-plugins=NodeRestriction,NamespaceAutomProvision        << Add NamespaceAutoProvision paramater

    # kubectl get pods          << check if the kube-api server Pod has come up




- Note that the NamespaceExists and NamespaceAutoProvision admission controllers are deprecated and now replaced by NamespaceLifecycle admission controller.

    - The NamespaceLifecycle admission controller will make sure that requests to a non-existent namespace is rejected and that the default namespaces such as default, kube-system and kube-public cannot be deleted.




- Now Disable DefaultStorageClass admission controller.

    - This admission controller observes creation of PersistentVolumeClaim objects that do not request any specific storage class and automatically adds a default storage class to them. This way, users that do not request any special storage class do not need to care about them at all and they will get the default one.

    - Note: Once you update kube-apiserver yaml file then please wait few mins for the kube-apiserver to restart completely.

    # vim /etc/kubernetes/manifests/kube-apiserver.yaml

    # cat /etc/kubernetes/manifests/kube-apiserver.yaml | grep -i disable
    - --disable-admission-plugins=DefaultStorageClass


- Since the kube-apiserver is running as pod you can check the process to see enabled and disabled plugins.

    # ps -ef | grep kube-apiserver | grep admission-plugins

    # ps -ef | grep -i kube-api | grep -i admission-plugins
        root       12953   12829  0 02:00 ?        00:00:05 kube-apiserver --advertise-address=192.9.0.6 --allow-privileged=true    --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.crt 
        --enable-admission-plugins=NodeRestriction,NamespaceAutoProvision 
        --disable-admission-plugins=DefaultStorageClass




##### Lab : Validating and Mutating Admission Controllers :

- Create namespace "webhook-demo" where we will deploy webhook components

    # kubectl create ns webhook-demo


- Create TLS secret webhook-server-tls for secure webhook communication in webhook-demo namespace.
    We have already created below cert and key for webhook server which should be used to create secret.

        Certificate : /root/keys/webhook-server-tls.crt

        Key : /root/keys/webhook-server-tls.key

    # kubectl -n webhook-demo create secret tls webhook-server-tls \
    --cert "/root/keys/webhook-server-tls.crt" \
    --key "/root/keys/webhook-server-tls.key"


- Create webhook deployment now.
    We have already added sample deployment definition under /root/webhook-deployment.yaml so just create deployment with that definition.

    # kubectl create -f /root/webhook-deployment.yaml 
    deployment.apps/webhook-server created



- Create webhook service now so that admission controller can communicate with webhook.

    We have already added sample service definition under /root/webhook-service.yaml so just create service with that definition.



- We have added MutatingWebhookConfiguration under /root/webhook-configuration.yaml.
    If we apply this configuration which resource and actions it will affect?     

        rules:
      - operations: [ "CREATE" ]
        apiGroups: [""]
        apiVersions: ["v1"]
        resources: ["pods"]
    admissionReviewVersions: ["v1beta1"]
    sideEffects: None

    >> Pod with create operations

    # kubectl create -f /root/webhook-configuration.yaml 
    mutatingwebhookconfiguration.admissionregistration.k8s.io/demo-webhook created



- # cat /root/webhook-configuration.yaml 
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name: demo-webhook
webhooks:
  - name: webhook-server.webhook-demo.svc
    clientConfig:
      service:
        name: webhook-server
        namespace: webhook-demo
        path: "/mutate"
      caBundle: LS0tLS1CRUdJTiBD
      ZwpGaUpraFA1bTJIcnk3U3NBS3h3VkhFZEVGUT09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    rules:
      - operations: [ "CREATE" ]
        apiGroups: [""]
        apiVersions: ["v1"]
        resources: ["pods"]
    admissionReviewVersions: ["v1beta1"]
    sideEffects: None

    - In previous steps we have deployed demo webhook which does below
    - Denies all request for pod to run as root in container if no securityContext is provided.
    - If no value is set for runAsNonRoot, a default of true is applied, and the user ID defaults to 1234
    - Allow to run containers as root if runAsNonRoot set explicitly to false in the securityContext

In next steps we have added some pod definitions file for each scenario. Deploy those pods with existing definitions file and validate the behaviour of our webhook .



- Deploy a pod with no securityContext specified. We have added pod definition file under /root/pod-with-defaults.yaml


- What are runAsNonRoot and runAsUser values for previously created pods securityContext?
    We did not specify any securityContext values in pod definition so check out the changes done by mutation webhook in pod

    # kubectl get po pod-with-defaults -o yaml | grep -A2 " securityContext:"
    securityContext:
        runAsNonRoot: true
        runAsUser: 1234



- Deploy pod with a securityContext explicitly allowing it to run as root.
    We have added pod definition file under /root/pod-with-override.yaml
        Validate securityContext after you deploy this pod.

        # kubectl apply -f /root/pod-with-override.yaml

        # kubectl get po pod-with-override -o yaml | grep -A2 " securityContext:"
          securityContext:
             runAsNonRoot: false
          serviceAccount: default




- Deploy a pod with a conflicting securityContext i.e. pod running with a user id of 0 (root)
    We have added pod definition file under /root/pod-with-conflict.yaml
    Mutating webhook should reject the request as its asking to run as root user without setting runAsNonRoot: false

    # kubectl apply -f /root/pod-with-conflict.yaml
    Error from server: error when creating "/root/pod-with-conflict.yaml": admission webhook "webhook-server.webhook-demo.svc" denied the request: runAsNonRoot specified, but runAsUser set to 0 (the root user)




##### Lab : OPA :

- Install and run OPA version v0.38.1 on the system in the background.

    Package should be opa_linux_amd64. Once downloaded, make package executable and run it as a server.

    - https://github.com/open-policy-agent/opa/releases
        Package: opa_linux_amd64

   # Find the given version of OPA from the release page.
        export VERSION=v0.38.1
        curl -L -o opa https://github.com/open-policy-agent/opa/releases/download/${VERSION}/opa_linux_amd64

        chmod 755 ./opa

        ./opa run -s &   



- Load policy /root/sample.rego to OPA with the name samplepolicy.

    # curl -X PUT --data-binary @sample.rego http://localhost:8181/v1/policies/samplepolicy




##### Lab : OPA in kubernetes :


- Create a configmap for OPA using the untrusted-registry.rego policy.

    Use below files:

        configmap file: /root/untrusted-registry.rego
        configmap name : untrusted-registry

    # kubectl create configmap untrusted-registry --from-file=untrusted-registry.rego
    configmap/untrusted-registry created




- Create a pod defined under /root/test.yaml in the namespace dev. Fix the OPA validation issue while creating the pod.

    # kubectl -n dev create -f /root/test.yaml 
    Error from server: error when creating "/root/test.yaml": 
    admission webhook "validating-webhook.openpolicyagent.org" denied the request: image 'nginx' comes from untrusted registry

    - Correct below line in /root/test.yaml

        # image: hooli.com/nginx

    - then run

        # kubectl apply -n dev -f /root/test.yaml
        # kubectl -n dev create -f /root/test.yaml 
        pod/test created



- Create a configmap named unique-host using the rego file /root/unique-host.rego for OPA

        # kubectl create configmap unique-host --from-file=/root/unique-host.rego 
        configmap/unique-host created



##### Lab : Manage secrets in kubernetes :


- How many secrets are defined in the dashboard-token secret?

    Run the command: kubectl describe secrets dashboard-token and look at the "data" field.
        There are three secrets - ca.crt, namespace and token.

    

- Create a new secret named db-secret with the data given below.

        Secret Name: db-secret
        Secret 1: DB_Host=sql01
        Secret 2: DB_User=root
        Secret 3: DB_Password=password123

    # kubectl create secret generic db-secret \
    > --from-literal=DB_Host=sql01 \
    > --from-literal=DB_User=root \
    > --from-literal=DB_Password=password123
    secret/db-secret created



- Configure webapp-pod to load environment variables from the newly created secret.
        
        # kubectl get pod webapp-pod -o yaml > webapp-pod.yaml

        # vim webapp-pod.yaml 
        Pod name: webapp-pod
        Image name: kodekloud/simple-webapp-mysql
        Env From: Secret=db-secret

        apiVersion: v1
        kind: Pod
        metadata:
        labels:
            name: webapp-pod
        name: webapp-pod
        namespace: default
        spec:
        containers:
        - image: kodekloud/simple-webapp-mysql
            imagePullPolicy: Always
            name: webapp
            envFrom:                            <<<< Add secrets here.
            - secretRef:
                name: db-secret
            volumeMounts:
            - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
            name: kube-api-access-kb9kb
            readOnly: true


        # kubectl delete pod webapp-pod --force

        # kubectl create -f webapp-pod.yaml 
            pod/webapp-pod created